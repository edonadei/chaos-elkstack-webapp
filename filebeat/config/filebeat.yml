filebeat.inputs: 
- type: docker 
  combine_partial: true 
  containers: 
    path: "/usr/share/filebeat/logs/containers" 
    stream: "stdout" 
    ids: "*" 
  # exclude_files: ['\.gz$\'] 
  ignore_older: 10m

# - type: log
# paths:
# - '/var/lib/docker/containers/*/*.log'
# json.message_key: log
# json.keys_under_root: true

processors: 
#   #decode the log field (sub JSON document) if JSON encoded, then maps it's fields to elasticsearch 
# - decode_json_fields: 
#   fields: ["log", "message"] 
#   target: "" #overwrite existing target elasticsearch fields while decoding json fields 
#   overwrite_keys: true 
- add_docker_metadata: 
    host: "unix:///var/run/docker.sock"

output.logstash:
  hosts: ["logstash:5044"]