version: "3"

services:       #Services à exécuter

  apache_img_1:     #Premier serveur apache à démarrer / Service 1
    container_name: ${COMPOSE_PROJECT_NAME}_con_apache_1
    build: ./apache/1     #tag de l'image construite
    restart: always
    expose:               #Ports de notre service (port interne)
      - ${APACHE_EXPOSED_PORT}
    networks:
      public_net:           #Custom name
        ipv4_address: ${APACHE_1_IP}

  apache_img_2:       #Deuxième serveur apache à démarrer / Service 2
    container_name: ${COMPOSE_PROJECT_NAME}_con_apache_2
    build: ./apache/2
    restart: always
    expose:
      - ${APACHE_EXPOSED_PORT}
    networks:
      public_net:
        ipv4_address: ${APACHE_2_IP}

  haproxy:            #Service haproxy : load balancing + proxy pour TCP et applications HTTP
    build: ./haproxy  
    container_name: ${COMPOSE_PROJECT_NAME}_haproxy_1
    ports:
      - 80:80
    expose:
      - 80
    networks:
      public_net:
        ipv4_address: ${HA_PROXY_IP}
    environment:      #Passage de notre shell actuel aux services des conteneurs ci-dessous
      - APACHE_1_IP=${APACHE_1_IP}
      - APACHE_2_IP=${APACHE_2_IP}
      - APACHE_EXPOSED_PORT=${APACHE_EXPOSED_PORT}
    restart: always

  # Chaos engineering, killing each 30s a container
  pumba:
    image: gaiaadm/pumba
    container_name: chaos_with_pumba
    restart: always
    #the --signal=SIGKILL would be definitely more effective, but no restart mechanic yet except the restart:always
    command: --interval=30s --random --log-level=info kill --signal=SIGTERM "re2:^${COMPOSE_PROJECT_NAME}" 
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    
  elasticsearch:
    build : ./elasticsearch
    container_name: elasticsearch
    restart: always
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms256m -Xmx256m
    networks:
      - elknet
    #data persitence
    volumes:
      - esdata:/usr/share/elasticsearch/data
      
  kibana:
    build : ./kibana
    container_name: kibana
    environment:
      SERVER_NAME : kibana
      #accessing elasticsearch url and port inside the subnet
      ELASTICSEARCH_URL : http://elasticsearch:9200
    #volumes:
     # - ./kibana/kibana.yml:/usr/share/kibana/config/kibana.yml
    networks:
      - elknet
    restart: always
  
  proxy:
    build : ./nginx
    container_name : proxy
    #the log server is accessible by 8081 port and redirected to 81
    ports:
      - "8081:81"
    networks:
      - elknet
    restart: always

  logstash:
    build : ./logstash
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml
      - ./logstash/pipeline/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
    environment:
      - ES_JAVA_OPTS=-Xms256m -Xmx256m
    networks:
      - elknet
    restart: always

  filebeat:
    build : ./filebeat
    user: "filebeat:filebeat"
    #to avoid errors as filebeat starts in few ms
    # depends_on:
    #   elasticsearch:
    #     condition: service_healthy
    #   kibana:
    #     condition: service_healthy
    #   logstash:
    #     condition: service_healthy
    volumes:
      - ./filebeat/config/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - /var/run/docker.sock:/usr/share/filebeat/docker.sock
      - /var/lib/docker/containers:/usr/share/filebeat/logs/containers
    networks:
      - elknet
    restart: always
    links:
      - elasticsearch
      - kibana

networks:
  public_net:
    driver: bridge
    ipam:
      config:
        - subnet: ${NETWORK_SUBNET}
  elknet:

volumes:
  esdata:
    driver: local
  logsApache1:
    driver: local
  logsApache2:
    driver: local
